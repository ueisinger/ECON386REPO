subsetselect <- subset(XYmerge, select=c(subset3, subset4, subset1, subest2))
View(subsetselect)
subsett3 <- grep("Subject", colnames(XYmerge), value=TRUE)
subset3 <- grep("Subject", colnames(XYmerge), value=TRUE)
subset4 <- grep("Activity", colnames(XYmerge), value=TRUE)
rm(subsett3, subest2)
subset2 <- grep("mean", colnames(XYmerge), value=TRUE)
subsetselect <- subset(XYmerge, select=c(subset3, subset4, subset1, subset2))
View(subsetselect)
subsetselect$Activity[subsetselect$Activity =="1"] <- "Walking"
subsetselect$Activity[subsetselect$Activity =="2"] <- "Walking_Upstairs"
subsetselect$Activity[subsetselect$Activity =="3"] <- "Walking_Downstairs"
subsetselect$Activity[subsetselect$Activity =="4"] <- "Sitting"
subsetselect$Activity[subsetselect$Activity =="5"] <- "Standing"
subsetselect$Activity[subsetselect$Activity =="6"] <- "Laying"
View(subsetselect)
?mean
?apply
mean(subsetselect, col="tBodyAcc-std()-X":"fBodyBodyGyroJerkMag-mean()")
aggregate.data.frame(subsetselect, by="tBodyAcc-std()-X":"fBodyBodyGyroJerkMag-mean()", FUN=mean)
aggregate(subsetselect, )
?grep
?sapply
?lapply
?rnorm
?runif
please <- data_frame(rnorm(10299), 10299, 79)
View(please)
rm(please)
please <- data.frame(Activity = c("Walking", "Walking_Upstairs","Walking_Downstairs",
"Sitting","Standing","Laying"),
Subject = c("1", "2", "3", "4",
"5", "6"),
tBodyAcc-std()-x = c(runif(3), rnorm(5)),
tBodyAcc-std()-y = c(runif(3), rnorm(5))
?market.values
please <- aggregate(x = subsetselect[c("tBodyAcc-std()-x","tBodyAcc-std()-y","tBodyAcc-std()-Z")],
by = subsetselect[c("Activity", "Subject")],
FUN = function(market.values){
sum(pmax(market.values, 0))
})
aggregate(subsetselect, list(Activity), mean)
aggregate(subsetselect, list("Activity"), mean)
aggregate(subsetselect, list("Activity" = subsetselect, "Subject" = subsetselect), mean)
source('~/Desktop/Task One 4.9.R')
new <- subsetselect
tidy <- read.csv("~/Desktop/ECONBD386/tidy.txt", sep="")
View(tidy)
please <-aggregate(yes$tBodyAcc-std()-x, by = list(yes$tBodyAcc-std()-x, yes$tBodyAcc-std()-y) , FUN = mean)
please <-aggregate(new$tBodyAcc-std()-x, by = list(new$tBodyAcc-std()-x, new$tBodyAcc-std()-y) , FUN = mean)
please <-aggregate(new$tBodyAcc-std()-x, by = list(new$"tBodyAcc-std()-x", new$"tBodyAcc-std()-y") , FUN = mean)
aggregate(Subject ~ Sctivity, data = new, c)
c(subsetselect$activity)
c(subsetselect$activity, NULL = FALSE)
c(subsetselect$activity, NA=TRUE)
c(subsetselect$activity, rm.na=TRUE)
View(new)
please <- aggregate((x=subsetselect$Subject by = list(example_data$tBodyAcc-std()-x, subsetselect$tBodyAcc-std()-y")
aggregate(x=subsetselect$Subject, by = list(example_data$tBodyAcc-std()-x, subsetselect$tBodyAcc-std()-y))
aggregate(x=subsetselect$Subject, by = list(example_data$tBodyAcc-std()-x, subsetselect$tBodyAcc-std()-y), FUN = mean)
aggregate(x=subsetselect$Subject, by = list(subsetselect$tBodyAcc-std()-x, subsetselect$tBodyAcc-std()-y), FUN = mean)
rm(new)
subject_group <- group_by(subsetselect, Subjects, add=TRUE)
activity_group <- group_by(subsetselect, Activity, add=TRUE)
subject_group <- group_by(subsetselect, Subject, add=TRUE)
final <- activity_group %<% summasise_all(c("mean", "sd"))
final <- activity_group %>% summasise_all(c("mean", "sd"))
final <- activity_group %>% summarise_all(c("mean", "sd"))
View(final)
?rmarkdown
??rmarkdown
---
title: "Project One: Code Book"
author: "U, Eisinger"
date: "4/15/2018"
output:
pdf_document
toc: true
toc_depth: 3
---
# Introduction and Description: Task One
The purpose of this code book is to demonstrate the data cleaning process used in Task One that was used to create the tidy data set. The data used for this project was from the "Human Activity Recognition Using Smartphone Dataset" obtained from the Non Linear Complex Systems Smart Laboratory at the University degli Studi di Genova. We began with seven different data sets: subject_train.txt, subject_test.txt, y_train.txt, y_test.txt, X_train.txt, X_test.txt, and featurest.txt. In this Task, we we merged the seven datasets together and cleaned the dataset according to Professor Levkoff's instructions.
The data was cleaned in the following way to show the means and the standard deviations for each feature for each activity per subject. This new dataset allows individuals to easily see the various average accelerometer and gyroscopre readings for the specific movements.
# Variable Names and Variable Labels
### Subject
There were 30 subjects, aged 19-48, that participated in this study with the Samsung Galaxy S II smartphone. Data was collected for each participants pertaining to each their six various activities and was obtained through determinind the means and standard deviations of each features data.
### Activity
The activities that were recorded were Walking, Walking_Upstairs, Walking_Downstairs, Sitting, Standing, and Laying. For each of these activities, the Samsung smartphone used various embedded technologies to record their movements in a seriees of features.
### tBodyAcc
The embedded accelerometer collected time domain signal data about body acceleration using three dimensional signals (X, Y, and Z).  Then means and standard deviations were extracted from the original dataset for each of the three dimensional signals.
### tGravityAcc
The embedded accelerometer collected time domain signal data of gravity acceleration using three dimensional signals (X, Y, and Z). The means and the standard deviations were extracted from the original dataset for each of the three signals.
### tBodyAccJerk
The embedded accelerometer collected time domain signal data of jerking movements using body linear accelerations and angular velocity. Data was collected using three dimensional signals (X, Y, Z). The means and the standard deviations were extracted from the original dataset for each of the three dimensional signals.
### tBodyGyro
The embedded gyroscope ccollected time domain signal data about body movements using three dimensional signals (X, Y, Z). The means and the standard deviations were extracted from the original dataset for each of the three signals.
###tBodyGyroJerk
The embedded gyroscope collected time domain signal data about body jerking movements using three dimensional signals (X, Y, and Z). Then means and standard deviations were extracted from the original dataset for each of the three dimensional signals.
###tBodyAccMag
The embedded accelerometer collected time domain signal data about body acceleration magnitudes. The magnitude of these signals was calculated using the Euclidean norm. The means and standard deviations were extracted from the original dataset to create these variables.
###tGravityAccMag
The embedded accelerometer collected time domain signal data about the gravity acceleration magnitude. The magnitude of these signals was calculated using the Euclidean norm. The means and the standard deviations were extracted from the original dataset to create this variable.
###tBodyAccJerkMag
The embedded accelerometer collected time domain signal data about the body acceleration jerking magnitude. The magnitude of these signals was calculated using the Euclidean norm. The mean and the standard deviation was extracted from the original dataset to create this variable.
###tBodyGyroMag
The embedded gryoscope collected time domain signal data about the body magnitude. The magnitude of these signals was calculated using the Euclidean norm. The mean and the standard deviation was extracted from the original dataset to create this variable.
###tBodyGyroJerkMag
The embedded gryoscope collected time domain signal data about the body jerking magnitude. The magnitude of these signals was calculated using the Euclidean norm. The mean and the standard deviation was extracted from the original dataset to create this variable.
###fBodyAcc
The embedded accelerometer collected frequency domain signal data about the body acceleration using three dimensional signals (X, Y, and Z). The means and the standard deviations was extracted from the original dataset for each dimension to create this variable.
###fBodyAccJerk
The embedded accelerometer collected frequency domain signal data about the body acceleration using three dimensional signals (X, Y, and Z). The means and the standard deviations was extracted from the original dataset for each dimension to create this variable.
###fBodyAccJerk
The embedded accelerometer collected frequency domain signal data about the body acceleration jerking using three dimensional signals (X, Y, and Z). The means and the standard deviations were extracted from the original dataset for each dimension to create this variable.
###fBodyGyro
The embedded gryoscope collected frequency domain signal data about the body movements using three dimensional signals (X, Y, and Z). The means and the standard deviations were extracted from the original dataset for each dimension to create this variable.
###fBodyAccMag
The embedded accelerometer collected frequency domain signal data about body acceleration magnitudes. The magnitude of these signals were calculated using the Euclidean norm. The means and the standard deviations were extracted from the original dataset to create this variable.
###fBodyBodyAccJerkMag
The embedded accelerometer collected frequency domain signal data about body acceleration jerking magnitudes. The magnitude of these signals were calculated using the Euclidean norm. The mean and the standard deviation was extracted from the original dataset to create this variable.
###fBodyBodyGyroMag
The embedded gryscope collected frequency domain signal data about the body movement magnitudes. The magnitude of these signals were calculated using the Euclidean norm. The mean and the standard deviation was extracted from the original dataset to create this variable.
###fBodyBodyGyroJerkMag
The embedded gryscope collected frequency domain signal data about the body jerking movement magnitudes. The magnitude of these three dimentional signals were calculated using the Euclidean norm. The mean and the standard deviation was extracted from the original dataset to create this variable.
##TASK ONE FINAL
rm(feat, filename, filename2, filename3, filename4, filename5, filename6, activity_group, features, final, newfeatures, subject, subject_group, subject_test, subject_train, subsetselect, subsetselect, testone, x_data, X_test, X_train, XYmerge, y_data, y_test, y_train)
##TASK ONE FINAL
knitr::opts_chunk$set(echo = TRUE)
getwd()
features <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/features.txt", quote="\"", comment.char="")
View(features)
subject_test <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/subject_test.txt", quote="\"", comment.char="")
View(subject_test)
subject_train <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/subject_train.txt", quote="\"", comment.char="")
View(subject_train)
y_test <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/y_test.txt", quote="\"", comment.char="")
View(y_test)
y_train <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/y_train.txt", quote="\"", comment.char="")
View(y_train)
X_test <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/X_test.txt", quote="\"", comment.char="")
View(X_test)
Headers <- read.table("~/Desktop/Econ386/ECON386REPO/Data Cleaning Project/Task 1/features.txt", quote="\"", comment.char="")
Headers <- read.table("features")
Headers[1] <- NULL
Headers <- read.table("features")
Headers <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/features.txt", quote="\"", comment.char="")
Headers[1] <- NULL
newHeaders=t(Headers)
subjects <- rbind(SubjectsTrain, SubjectsTest)
X_train <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/X_train.txt", quote="\"", comment.char="")
View(X_train)
subjects <- rbind(subjects_train, subject_test)
subjects <- rbind(subject_train, subject_test)
XVariable <- rbind(X_train, X_test)
YVariable <- rbind(y_train, y_test)
XYmerge <- cbind(subjects, YVariable, XVariable)
names(XYmerge) <- c("Subjects", "Activity", newHeaders)
library(dplyr)
subset1 <-grep("std", colnames(XYmerge), value = TRUE)
subset2 <-grep("mean", colnames(XYmerge), value = TRUE)
subset3 <- grep("Activity", colnames(XYmerge), value = TRUE)
subset4 <- grep("Subjects", colnames(XYmerge), value = TRUE)
subsetselect <-subset(XYmerge, select=c(subset4, subset3, subset1, subset2))
subsetselect <-subset(XYmerge, select=c(subset4, subset3, subset1, subset2))
subsetselect$Activity([subsetselect$Activity =="1"] <- "WALKING", [subsetselect$Activity =="2"] <- "WALKING_UPSTAIRS",
[subsetselect$Activity =="3"] <- "WALKING_DOWNSTAIRS", [subsetselect$Activity =="4"] <- "SITTING",
[subsetselect$Activity =="5"] <- "STANDING", [subsetselect$Activity =="6"] <- "LAYING")
subsetselect$Activity[subsetselect$Activity =="1"] <- "WALKING"
subsetselect$Activity[subsetselect$Activity =="2"] <- "WALKING_UPSTAIRS"
subsetselect$Activity[subsetselect$Activity =="3"] <- "WALKING_DOWNSTAIRS"
subsetselect$Activity[subsetselect$Activity =="4"] <- "SITTING"
subsetselect$Activity[subsetselect$Activity =="5"] <- "STANDING"
subsetselect$Activity[subsetselect$Activity =="6"] <- "LAYING"
subject_group <- group_by(subsetselect, Subjects, add=TRUE)
activity_group <- group_by(subject_group, Activity, add=TRUE)
finalTable <- activity_group %>% summarise_all(c("mean", "sd"))
View(finalTable)
View(tidy)
rm(finalTable)
finalTable <- activity_group %>% summarise_all(c("mean))
finalTable <- activity_group %>% summarise_all(c("mean")
finalTable <- activity_group %>% summarise_all(c("mean")
finalTable <- activity_group %>% summarise_all(c("mean
finalTable <- activity_group %>% summarise_all(c("mean"))
finalTable2 <- activity_group %>% summarise_all(c("std"))
rm(finalTable)
?summarise
rm(finalTable)
View(activity_group)
bigtable <- table(activity_group$Subjects,activity_group$fBodyBodyGyroJerkMag-mean)
summarise_at(activity_group.tbl, c(Subjects:fBodyBodyGyroJerkMag-meanFreq()).vars)
summarise_at(activity_group.tbl, c(Subjects:fBodyBodyGyroJerkMag-meanFreq()).vars)
finalTable <- activity_group %>% summarise_all(c("mean, std"))
finalTable <- activity_group %>% summarise_all(c("mean, sd"))
finalTable <- activity_group %>% summarise_all(c("mean", "sd"))
View(finalTable)
finalTable2 <- finalTable[, -c(3:4)]
View(finalTable2)
rm(finalTable2)
write.table(x, file = "Cleaned Dataset", append = FALSE, quote = TRUE, sep = " ",
eol = "\n", na = "NA", dec = ".", row.names = FALSE,
col.names = TRUE, qmethod = c("escape", "double"),
fileEncoding = "")
write.table(finalTable, file = "Cleaned Dataset", append = FALSE, quote = TRUE, sep = " ",
eol = "\n", na = "NA", dec = ".", row.names = FALSE,
col.names = TRUE, qmethod = c("escape", "double"),
fileEncoding = "")
finalTable <- activity_group %>% summarise_all(c("mean"))
rm(finalTable)
finalTable <- activity_group %>% summarise_all(c("mean"))
library(ggplot2)
means <- ddply(finalTable, "WALKING", summarise, means=colnames(c(3:81)))
means <- ddply(finalTable, "WALKING", summarise, means=colnames(c(3:81)))
View(finalTable)
View(Headers)
cd
getwd()
setwd("/Users/andreabohneisinger/Desktop/ECONBD386/Project One 4.17.18")
setwd("/Users/andreabohneisinger/Desktop/ECONBD386/Data Cleaning Project/Task 2)
filepath<-"/Users/KevinChang/Desktop"  #you'll obviously need to change this to yours
filename<-"Panel_8595.csv"
setwd("/Users/andreabohneisinger/Desktop/ECONBD386/Data Cleaning Project/Task 2")
Panel_8595 <- read.csv("~/Desktop/ECONBD386/Data Cleaning Project/Task 2/Panel_8595.Txt")
View(Panel_8595)
getwd()
setwd("/Users/andreabohneisinger/Desktop")
filepath <- "/Users/andreabohneisinger/Desktop"
setwd(filepath)
filename <- "Panel_8595.csv"
Dataset <- read.csv(filename)
##Renaming the variables.
colnames(Dataset)[colnames(Dataset)=="QQ.kt.t.v."] <- "Plant_I.D."
filename <- "Panel_8595.Txt"
Dataset <- read.csv(filename)
##Renaming the variables.
colnames(Dataset)[colnames(Dataset)=="QQ.kt.t.v."] <- "Plant_I.D."
colnames(Dataset)[colnames(Dataset)=="X.1"] <- "Year"
colnames(Dataset)[colnames(Dataset)=="X2"] <- "Employees"
colnames(Dataset)[colnames(Dataset)=="X5"] <- "Heat_Content_of_Gas"
colnames(Dataset)[colnames(Dataset)=="X4"] <- "Heat_Content_of_Oil"
colnames(Dataset)[colnames(Dataset)=="X3"] <- "Heat_Content_of_Coal"
colnames(Dataset)[colnames(Dataset)=="Y2"] <- "Sulfur_Dioxide"
colnames(Dataset)[colnames(Dataset)=="Y3"] <- "Nitrious_Oxide"
colnames(Dataset)[colnames(Dataset)=="Y1"] <- "Electricity"
colnames(Dataset)[colnames(Dataset)=="X1"] <- "Dollars"
##View the dataset.
View(Dataset)
##Convert all energy measurements (energy produced and heat contents) into daily averages, measured in Mwh.
Dataset <- transform(Dataset, Electricity = Dataset$Electricity/1000)
Dataset <- transform(Dataset, Electricity = Dataset$Electricity/365)
rm(activity_group, features, Headers, finalTable, newHeaders, subject_group, subject_test, subject_train, subjects, X_test, X_train, XVariable, XYmerge, y_test, y_train, YVariable, subset1, subset2, subset2, subset3, subset4)
rm(subsetselect)
##View the dataset.
View(Dataset)
View(Dataset)
setwd(filepath)
filename <- "Panel_8595.Txt"
Dataset <- read.csv(filename)
View(Dataset)
##Renaming the variables.
colnames(Dataset)[colnames(Dataset)=="QQ.kt.t.v."] <- "Plant_I.D."
View(Dataset)
colnames(Dataset)[colnames(Dataset)=="X.1"] <- "Year"
colnames(Dataset)[colnames(Dataset)=="X2"] <- "Employees"
colnames(Dataset)[colnames(Dataset)=="X5"] <- "Heat_Content_of_Gas"
colnames(Dataset)[colnames(Dataset)=="X4"] <- "Heat_Content_of_Oil"
colnames(Dataset)[colnames(Dataset)=="X3"] <- "Heat_Content_of_Coal"
colnames(Dataset)[colnames(Dataset)=="Y2"] <- "Sulfur_Dioxide"
colnames(Dataset)[colnames(Dataset)=="Y3"] <- "Nitrious_Oxide"
colnames(Dataset)[colnames(Dataset)=="Y1"] <- "Electricity"
colnames(Dataset)[colnames(Dataset)=="X1"] <- "Dollars"
View(Dataset)
##Convert all energy measurements (energy produced and heat contents) into daily averages, measured in Mwh.
Dataset <- transform(Dataset, Electricity = Dataset$Electricity/1000)
Dataset <- transform(Dataset, Electricity = Dataset$Electricity/365)
Panel_8595 <- read.csv("~/Desktop/Panel_8595.Txt")
View(Panel_8595)
colnames(Dataset) <- c("Plant_I.D.", "Year", "Employees", "Heat_Content_of_Gas", "Heat_Content_of_Oil", "Heat_Content_of_Coal", "Sulfur_Dioxide", "Nitrious_Oxide", "Electricity", "Dollars")
?c
colnames(Dataset) <- c(Dataset, "Plant_I.D.", "Year", "Employees", "Heat_Content_of_Gas", "Heat_Content_of_Oil", "Heat_Content_of_Coal", "Sulfur_Dioxide", "Nitrious_Oxide", "Electricity", "Dollars")
colnames(Dataset)[(names(Dataset) == "QQ.kt.t.v.")] <- "Plant_I.D."
View(Dataset)
colnames(Dataset)[(names(Dataset) == "X.1")] <- "Year"
View(Dataset)
##Loading the file into R.
filename<-"Panel_8595.csv"
Dataset<-read.csv(filename)
##Loading the file into R.
filename<-"PanelData.csv"
Dataset<-read.csv(filename)
colnames(Dataset)[colnames(Dataset)=="QQ.kt.t.v."] <- "Plant_I.D."
colnames(Dataset)[colnames(Dataset)=="X.1"] <- "Year"
colnames(Dataset)[colnames(Dataset)=="X2"] <- "Employees"
colnames(Dataset)[colnames(Dataset)=="X5"] <- "Heat_Content_of_Gas"
colnames(Dataset)[colnames(Dataset)=="X4"] <- "Heat_Content_of_Oil"
colnames(Dataset)[colnames(Dataset)=="X3"] <- "Heat_Content_of_Coal"
colnames(Dataset)[colnames(Dataset)=="Y2"] <- "Sulfur_Dioxide"
colnames(Dataset)[colnames(Dataset)=="Y3"] <- "Nitrious_Oxide"
colnames(Dataset)[colnames(Dataset)=="Y1"] <- "Electricity"
colnames(Dataset)[colnames(Dataset)=="X1"] <- "Dollars"
##View the dataset.
View(Dataset)
colnames(Dataset)[colnames(Dataset)=="X.2"] <- "Employees"
colnames(Dataset)[colnames(Dataset)=="X.5"] <- "Heat_Content_of_Gas"
colnames(Dataset)[colnames(Dataset)=="X.4"] <- "Heat_Content_of_Oil"
colnames(Dataset)[colnames(Dataset)=="X.3"] <- "Heat_Content_of_Coal"
colnames(Dataset)[colnames(Dataset)=="Y.2"] <- "Sulfur_Dioxide"
colnames(Dataset)[colnames(Dataset)=="Y.3"] <- "Nitrious_Oxide"
colnames(Dataset)[colnames(Dataset)=="Y.1"] <- "Electricity"
colnames(Dataset)[colnames(Dataset)=="X.1"] <- "Dollars"
##View the dataset.
View(Dataset)
colnames(Dataset)[colnames(Dataset)=="X.3"] <- "Heat_Content_of_Coal"
colnames(Dataset)[colnames(Dataset)=="Y2"] <- "Sulfur_Dioxide"
colnames(Dataset)[colnames(Dataset)=="Y3"] <- "Nitrious_Oxide"
colnames(Dataset)[colnames(Dataset)=="Y1"] <- "Electricity"
colnames(Dataset)[colnames(Dataset)=="X1"] <- "Dollars"
##--Start N.Kingery--
##Transposing the Header object so that the data frame changes from 1 column, 561 rows to 561 columns, 1 row. This also changes the data type to char.
newHeaders=t(Headers)
##--Start U.Eisinger--
##Setting the correct working directory.
rm(list = ls())
getwd()
setwd()
##Importing the data from the txt files from the Econ386Repo, and saving them as objects.
XTrain <- read.table("~/Desktop/Econ386/ECON386REPO/Data Cleaning Project/Task 1/X_train.txt", quote="\"", comment.char="")
##--D.Chang and J.Watkins--
##Setting the current working directory to where the .txt file is on your computer.
getwd()
setwd("/Users/andreabohneisinger/Desktop/ECONBD386/Data Cleaning Project/Task 2")
##Loading the file into R.
Dataset <- read.table("~/Desktop/Econ386/ECON386REPO/Data Cleaning Project/Task 2/Panel_8595.Txt", skip = 2)
##Loading the file into R.
Dataset <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 2/Panel_8595.Txt", skip = 2)
##Renaming the variables.
Dataset[2] <- NULL
##Renaming the variables.
Dataset[2] <- NULL
names(Dataset) <- c("Plant_I.D.", "Year", "ElectricityKWH", "Sulfur_Dioxide_Daily", "Nitrous_Oxide_Daily", "Dollars_Millions",
"Employees", "Heat_Content_of_Coal_Daily","Heat_Content_of_Oil_Daily", "Heat_Content_of_Gas_Daily")
##Convert all energy measurements (energy produced and heat contents) into daily averages, measured in Mwh.
Dataset <- transform(Dataset, ElectricityKWH = Dataset$ElectricityKWH/1000000)
Dataset <- transform(Dataset, Heat_Content_of_Gas_Daily = Dataset$Heat_Content_of_Gas_Daily*0.29307/365000000000)
Dataset <- transform(Dataset, Heat_Content_of_Oil_Daily = Dataset$Heat_Content_of_Oil_Daily*0.29307/365000000000)
Dataset <- transform(Dataset, Heat_Content_of_Coal_Daily = Dataset$Heat_Content_of_Coal_Daily*0.29307/365000000000)
View(Dataset)
##Convert all pollutants quantities, measured in annualized short tons, into daily averages.
Dataset <- transform(Dataset, Sulfur_Dioxide_Daily = Dataset$Sulfur_Dioxide_Daily/365)
Dataset <- transform(Dataset, Nitrous_Oxide_Daily = Dataset$Nitrous_Oxide_Daily/365)
View(Dataset)
##Convert all dollars (measured in 1973 $’s) into 2017 dollars.
Dataset <- transform(Dataset, Dollars_Millions = Dataset$Dollars_Millions*5.5132/1000000)
View(Dataset)
##Add a factor variable indicating whether or not Phase I of the Clean Air Act had already been announced or not (the CAA Phase I restrictions were announced in 1990).
Dataset$CAA <- ifelse(Dataset$Year>=90, 1, 0)
View(Dataset)
Dataset[11:12] <- NULL
##Create tidy2.txt file.
write.table(Dataset, file = "tidy2.txt")
View(Dataset)
##Creating separate dataframes that contain the averages of each variable.
tidy2a_1 <- aggregate(Electricity ~ Plant_I.D. , data=tidy2b, mean)
##--Start U.Eisinger--
##Setting the correct working directory.
rm(list = ls())
getwd()
setwd("/Users/andreabohneisinger/Desktop/ECONBD386/Data Cleaning Project/Task 1")
##Importing the data from the txt files from the Econ386Repo, and saving them as objects.
XTrain <- read.table("~/Desktop/Econ386/ECON386REPO/Data Cleaning Project/Task 1/X_train.txt", quote="\"", comment.char="")
##Importing the data from the txt files from the Econ386Repo, and saving them as objects.
XTrain <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/X_train.txt", quote="\"", comment.char="")
XTest <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/X_test.txt", quote="\"", comment.char="")
YTrain <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/y_train.txt", quote="\"", comment.char="")
YTest <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/y_test.txt", quote="\"", comment.char="")
SubjectsTrain <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/subject_train.txt", quote="\"", comment.char="")
SubjectsTest <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/subject_test.txt", quote="\"", comment.char="")
##Setting the first column that has numbers assigned to headers to null.
Headers <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/features.txt", quote="\"", comment.char="")
Headers[1] <- NULL
##--Start N.Kingery--
##Transposing the Header object so that the data frame changes from 1 column, 561 rows to 561 columns, 1 row. This also changes the data type to char.
newHeaders=t(Headers)
##Merging the data into the same columns and rows.
subjects <- rbind(SubjectsTrain, SubjectsTest)
XVariable <- rbind(XTrain, XTest)
##--Start U.Eisinger--
##Setting the correct working directory.
rm(list = ls())
getwd()
setwd("/Users/andreabohneisinger/Desktop/ECONBD386/Data Cleaning Project/Task 1")
##Importing the data from the txt files from the Econ386Repo, and saving them as objects.
XTrain <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/X_train.txt", quote="\"", comment.char="")
XTest <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/X_test.txt", quote="\"", comment.char="")
YTrain <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/y_train.txt", quote="\"", comment.char="")
YTest <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/y_test.txt", quote="\"", comment.char="")
SubjectsTrain <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/subject_train.txt", quote="\"", comment.char="")
SubjectsTest <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/subject_test.txt", quote="\"", comment.char="")
##Setting the first column that has numbers assigned to headers to null.
Headers <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 1/features.txt", quote="\"", comment.char="")
Headers[1] <- NULL
##--Start N.Kingery--
##Transposing the Header object so that the data frame changes from 1 column, 561 rows to 561 columns, 1 row. This also changes the data type to char.
newHeaders=t(Headers)
##Merging the data into the same columns and rows.
subjects <- rbind(SubjectsTrain, SubjectsTest)
XVariable <- rbind(XTrain, XTest)
YVariable <- rbind(YTrain, YTest)
XYmerge <- cbind(subjects, YVariable, XVariable)
##Changing the name of the header row to be Subjects, Activity and the strings of newHeaders.
names(XYmerge) <- c("Subjects", "Activity", newHeaders)
##--Start M.Stephens--
##Selecting columns individually with subject, activity, std, mean, and then subsetting into a new table.
library(dplyr)
subset1 <-grep("std", colnames(XYmerge), value = TRUE)
subset2 <-grep("mean", colnames(XYmerge), value = TRUE)
subset3 <- grep("Activity", colnames(XYmerge), value = TRUE)
subset4 <- grep("Subjects", colnames(XYmerge), value = TRUE)
subsetselect <-subset(XYmerge, select=c(subset4, subset3, subset1, subset2))
##Renaming the activity column so that the numbers change to the actual activity.
subsetselect$Activity[subsetselect$Activity =="1"] <- "WALKING"
subsetselect$Activity[subsetselect$Activity =="2"] <- "WALKING_UPSTAIRS"
subsetselect$Activity[subsetselect$Activity =="3"] <- "WALKING_DOWNSTAIRS"
subsetselect$Activity[subsetselect$Activity =="4"] <- "SITTING"
subsetselect$Activity[subsetselect$Activity =="5"] <- "STANDING"
subsetselect$Activity[subsetselect$Activity =="6"] <- "LAYING"
##Grouping the subjects and activities into subgroups.
subject_group <- group_by(subsetselect, Subjects, add=TRUE)
activity_group <- group_by(subject_group, Activity, add=TRUE)
##Summarizing each subject with the mean and standard deviation of each of the six activities.
finalTable <- activity_group %>% summarise_all(c("mean"))
##Used to save results as a file called tidy1.txt
write.table(finalTable, file="tidy1.txt")
rm(list=ls())
##--D.Chang and J.Watkins--
##Setting the current working directory to where the .txt file is on your computer.
getwd()
setwd("/Users/andreabohneisinger/Desktop/ECONBD386/Data Cleaning Project/Task 2")
rm(list=ls())
##Loading the file into R.
Dataset <- read.table("~/Desktop/ECONBD386/Data Cleaning Project/Task 2/Panel_8595.Txt", skip = 2)
##Renaming the variables.
Dataset[2] <- NULL
names(Dataset) <- c("Plant_I.D.", "Year", "ElectricityKWH", "Sulfur_Dioxide_Daily", "Nitrous_Oxide_Daily", "Dollars_Millions",
"Employees", "Heat_Content_of_Coal_Daily","Heat_Content_of_Oil_Daily", "Heat_Content_of_Gas_Daily")
##Convert all energy measurements (energy produced and heat contents) into daily averages, measured in Mwh.
Dataset <- transform(Dataset, ElectricityKWH = Dataset$ElectricityKWH/1000000)
Dataset <- transform(Dataset, Heat_Content_of_Gas_Daily = Dataset$Heat_Content_of_Gas_Daily*0.29307/365000000000)
Dataset <- transform(Dataset, Heat_Content_of_Oil_Daily = Dataset$Heat_Content_of_Oil_Daily*0.29307/365000000000)
Dataset <- transform(Dataset, Heat_Content_of_Coal_Daily = Dataset$Heat_Content_of_Coal_Daily*0.29307/365000000000)
View(Dataset)
##Convert all pollutants quantities, measured in annualized short tons, into daily averages.
Dataset <- transform(Dataset, Sulfur_Dioxide_Daily = Dataset$Sulfur_Dioxide_Daily/365)
Dataset <- transform(Dataset, Nitrous_Oxide_Daily = Dataset$Nitrous_Oxide_Daily/365)
View(Dataset)
##Convert all dollars (measured in 1973 $’s) into 2017 dollars.
Dataset <- transform(Dataset, Dollars_Millions = Dataset$Dollars_Millions*5.5132/1000000)
View(Dataset)
##Add a factor variable indicating whether or not Phase I of the Clean Air Act had already been announced or not (the CAA Phase I restrictions were announced in 1990).
Dataset$CAA <- ifelse(Dataset$Year>=90, 1, 0)
View(Dataset)
Dataset[11:12] <- NULL
##Create tidy2.txt file.
write.table(Dataset, file = "tidy2.txt")
View(Dataset)
##Creating separate dataframes that contain the averages of each variable.
tidy2a_1 <- aggregate(Electricity ~ Plant_I.D. , data=tidy2b, mean)
##Creating separate dataframes that contain the averages of each variable.
tidy2a_1 <- aggregate(Electricity ~ Plant_I.D. , data=Dataset, mean)
##Creating separate dataframes that contain the averages of each variable.
tidy2a_1 <- aggregate(ElectricityKWH ~ Plant_I.D. , data=Dataset, mean)
tidy2a_2 <- aggregate(Sulfur_Dioxide_Daily ~ Plant_I.D. , data=Dataset, mean)
tidy2a_3 <- aggregate(Nitrous_Oxide_Daily ~ Plant_I.D. , data=Dataset, mean)
tidy2a_4 <- aggregate(Dollars_Millions ~ Plant_I.D. , data=Dataset, mean)
tidy2a_5 <- aggregate(Employees ~ Plant_I.D. , data=Dataset, mean)
tidy2a_6 <- aggregate(Heat_Content_of_Coal_Daily ~ Plant_I.D. , data=Dataset, mean)
tidy2a_7 <- aggregate(Heat_Content_of_Oil_Daily ~ Plant_I.D. , data=Dataset, mean)
tidy2a_8 <- aggregate(Heat_Content_of_Gas_Daily ~ Plant_I.D. , data=Dataset, mean)
tidy2a_9 <- aggregate(CAA ~ Plant_I.D. , data=Dataset, mean)
##Merging the dataframes together.
tidy2a_0<-(Reduce(function(x, y) merge(x, y, all=TRUE), list(tidy2a_1, tidy2a_2, tidy2a_3,tidy2a_4,tidy2a_5,tidy2a_6,tidy2a_7,tidy2a_8,tidy2a_9)))
View(tidy2a_0)
##Create the tidy2_a.txt file.
write.table(tidy2a_0,"tidy_2a.txt")
##Creating separate dataframes that contain the sum of each variable.
tidy2b_1 <- aggregate(ElectricityKWH ~ Year , data=Dataset, sum)
tidy2b_2 <- aggregate(Sulfur_Dioxide_Daily ~ Year , data=Dataset, sum)
tidy2b_3 <- aggregate(Nitrous_Oxide_Daily ~ Year , data=Dataset, sum)
tidy2b_4 <- aggregate(Dollars_Millions ~ Year , data=Dataset, sum)
tidy2b_5 <- aggregate(Employees ~ Year , data=Dataset, sum)
tidy2b_6 <- aggregate(Heat_Content_of_Coal_Daily ~ Year , data=Dataset, sum)
tidy2b_7 <- aggregate(Heat_Content_of_Oil_Daily ~ Year , data=Dataset, sum)
tidy2b_8 <- aggregate(Heat_Content_of_Gas_Daily ~ Year , data=Dataset, sum)
tidy2b_9 <- aggregate(CAA ~ Year , data=Dataset, sum)
##Merging the dataframes.
tidy2b_0<-(Reduce(function(x, y) merge(x, y, all=TRUE), list(tidy2b_1, tidy2b_2, tidy2b_3,tidy2b_4,tidy2b_5,tidy2b_6,tidy2b_7,tidy2b_8,tidy2b_9)))
View(tidy2b_0)
##Create the tidy2_b.txt file.
write.table(tidy2b_0,"tidy_2b.txt")
summary(tidy2a_0)
summary(tidy2b_0)
dim(tidy2a_0)
dim(tidy2b_0)
head(tidy2a_0)
hist(tidy2a_0)
ggplot(tidy2a_0)
View(tidy2b_0)
cool <- ggplot(tidy2b_0, aes(x=Year)) + geom_histogram(aes(y=...ElectricityKWH...), position = "identity")
View(cool)
library(datasets)
library(ggplot2)
library(plyr)
